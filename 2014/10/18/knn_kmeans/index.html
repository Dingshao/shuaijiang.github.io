<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>K近邻法与k-means | shuaijiang's blog</title>
  <meta name="author" content="shuaijiang">
  
  <meta name="description" content="简介
K近邻法（knn）是一种基本的分类与回归方法。k-means是一种简单而有效的聚类方法。虽然两者用途不同、解决的问题不同，但是在算法上有很多相似性，于是将二者放在一起，这样能够更好地对比二者的异同。
算法描述
knn
算法思路：如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。
k近邻模型的三个基本要素：

k值的选择：k值的选择会对结果产生重大影响。较小的k值可以减少近似误差，但是会增加估计误差；较大的k值可以减小估计误差，但是会增加近似误差。一般而言，通常采用交叉验证法来选取最优的k值。
距离度量：距离反映了特征空间中两个实例的相似程度。可以采用欧氏距离、曼哈顿距离等。
分类决策规则：往往采用多数表决。

k-means
算法步骤：1. 从n个数据中随机选择 k 个对象作为初始聚类中心；2. 根据每个聚类对象的均值（中心对象），计算每个数据点与这些中心对象的距离；并根据最小距离准则，重新对数据进行划分；3. 重新计算每个有变化的聚类簇的均值，选择与均值距离最小的数据作为中心对象；4. 循环步骤2和3，直到每个聚类簇不再发生变化为止。
k-means方法的基本要素：

k值的选择：也就是类别的确定，与K近邻中k值的确定方法类似。
距离度量：可以采用欧氏距离、曼哈顿距离等。">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="K近邻法与k-means"/>
  <meta property="og:site_name" content="shuaijiang's blog"/>

  
    <meta property="og:image" content="undefined"/>
  

	
  	  <!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
	

  <link href="/favicon.png" rel="icon">
  <link rel="alternate" href="/atom.xml" title="shuaijiang's blog" type="application/atom+xml">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
  

</head>


<script type="text/javascript">
	var _bdhmProtocol = (("https:" == document.location.protocol) ? " https://" : " http://");
	document.write(unescape("%3Cscript src='" + _bdhmProtocol + "hm.baidu.com/h.js%3F95b0561258b05b5d31ceabbff82500dc' type='text/javascript'%3E%3C/script%3E"));
</script>

<body>
  <header id="header" class="inner"><div class="alignleft">
  <h1><a href="/">shuaijiang's blog</a></h1>
  <h2><a href="/"></a></h2>
</div>
<nav id="main-nav" class="alignright">
  <ul>
    
      <li><a href="/">Home</a></li>
    
      <li><a href="/archives">Archives</a></li>
    
      <li><a href="/about">About</a></li>
    
  </ul>
  <div class="clearfix"></div>
</nav>
<div class="clearfix"></div></header>
  <div id="content" class="inner">
    <div id="main-col" class="alignleft"><div id="wrapper"><article class="post">
  
  <div class="post-content">
    <header>
      
        <div class="icon"></div>
        <time datetime="2014-10-18T07:39:59.000Z"><a href="/2014/10/18/knn_kmeans/">10月 18 2014</a></time>
      
      
  
    <h1 class="title">K近邻法与k-means</h1>
  

    </header>
    <div class="entry">
      
        <h1>简介</h1>
<p>K近邻法（knn）是一种基本的分类与回归方法。k-means是一种简单而有效的聚类方法。虽然两者用途不同、解决的问题不同，但是在算法上有很多相似性，于是将二者放在一起，这样能够更好地对比二者的异同。</p>
<h1>算法描述</h1>
<h2>knn</h2>
<p>算法思路：<br>如果一个样本在特征空间中的k个最相似(即特征空间中最邻近)的样本中的大多数属于某一个类别，则该样本也属于这个类别。</p>
<p>k近邻模型的三个基本要素：</p>
<ol>
<li>k值的选择：k值的选择会对结果产生重大影响。较小的k值可以减少近似误差，但是会增加估计误差；较大的k值可以减小估计误差，但是会增加近似误差。一般而言，通常采用交叉验证法来选取最优的k值。</li>
<li>距离度量：距离反映了特征空间中两个实例的相似程度。可以采用欧氏距离、曼哈顿距离等。</li>
<li>分类决策规则：往往采用多数表决。</li>
</ol>
<h2>k-means</h2>
<p>算法步骤：<br>1. 从n个数据中随机选择 k 个对象作为初始聚类中心；<br>2. 根据每个聚类对象的均值（中心对象），计算每个数据点与这些中心对象的距离；并根据最小距离准则，重新对数据进行划分；<br>3. 重新计算每个有变化的聚类簇的均值，选择与均值距离最小的数据作为中心对象；<br>4. 循环步骤2和3，直到每个聚类簇不再发生变化为止。</p>
<p>k-means方法的基本要素：</p>
<ol>
<li>k值的选择：也就是类别的确定，与K近邻中k值的确定方法类似。</li>
<li>距离度量：可以采用欧氏距离、曼哈顿距离等。<a id="more"></a>



</li>
</ol>
<h1>应用实例</h1>
<h2>问题描述</h2>
<p>已知若干人的性别、身高和体重，给定身高和体重判断性别。考虑使用k近邻算法实现性别的分类，使用k-means实现性别的聚类。</p>
<h2>数据</h2>
<p>数据集合：<a href="https://github.com/shuaijiang/FemaleMaleDatabase" title="https://github.com/shuaijiang/FemaleMaleDatabase" target="_blank"><a href="https://github.com/shuaijiang/FemaleMaleDatabase">https://github.com/shuaijiang/FemaleMaleDatabase</a></a></p>
<p>该数据集包含了训练数据集和测试数据集，考虑在该数据集上利用k近邻算法和k-means方法分别实现性别的分类和聚类。</p>
<p>将训练数据展示到图中，可以更加直观地观察到数据样本之间的联系和差异，以及不同性别之间的差异。<br><img src="/image/male_female.png" alt="数据展示"></p>
<h2>KNN的分类结果</h2>
<p>KNN算法中的基本设置</p>
<ul>
<li>k=5</li>
<li>距离度量：欧氏距离</li>
<li>分类决策规则：多数投票</li>
<li>测试集：<a href="https://github.com/shuaijiang/FemaleMaleDatabase/blob/master/test0.txt" title="test0" target="_blank"><a href="https://github.com/shuaijiang/FemaleMaleDatabase/blob/master/test0.txt">https://github.com/shuaijiang/FemaleMaleDatabase/blob/master/test0.txt</a></a></li>
</ul>
<p>利用KNN算法，在测试集上的结果如下混淆矩阵表所示。从表中可以看出，测试集中的男性全部分类正确，测试集中的女性有一个被错误分类，其他都分类正确。</p>
<blockquote>
<table border="1" align="center" valign="center">  <tr><th>混淆矩阵</th><td>Test:male</td><td>Test:female</td></tr>    <tr><td>Result:male</td><td align="center">20</td><td align="center" >1</td></tr>  <tr><td>Result:female</td><td align="center">0</td><td align="center">14</td></tr> </table>

</blockquote>
<p>（表注：Test:male、Test:female分别表示测试集中的男性和女性，Result:male和Result:female分别表示结果中的男性和女性。表格中第一个元素：即Test:male列、Result：male行，表示测试集中为男性、并且结果中也为男性的数目。表格中其他元素所代表的含义以此类推）<br>由上表可以计算分类的正确率：(20+14)/(20+14+1) = <strong>97.14%</strong></p>
<h2>K-means的聚类结果</h2>
<p>K-means算法的基本设置</p>
<ul>
<li>k=2</li>
<li>距离度量：欧氏距离</li>
<li>最大聚类次数：200</li>
<li>类别决策规则：根据每个聚类簇中的多数决定类别</li>
<li>测试集：<a href="https://github.com/shuaijiang/FemaleMaleDatabase/blob/master/test0.txt" target="_blank"><a href="https://github.com/shuaijiang/FemaleMaleDatabase/blob/master/test0.txt">https://github.com/shuaijiang/FemaleMaleDatabase/blob/master/test0.txt</a></a></li>
</ul>
<blockquote>
<table border="1" align="center" valign="center">  <tr><th>混淆矩阵</th><td>Test:male</td><td>Test:female</td></tr>    <tr><td>Result:male</td><td align="center">20</td><td align="center" >1</td></tr>  <tr><td>Result:female</td><td align="center">0</td><td align="center">14</td></tr> </table>

</blockquote>
<p>（表注：该表与上表内容一致）</p>
<p>由于选择初始中心点是随机的，所以每次的聚类结果都不相同，最好的情况下能够完全聚类正确，最差的情况下两个聚类簇没有分开，根据多数投票决定类别时，被标记为同一个类别。</p>
<h1>KNN VS K-means</h1>
<p>二者的相同点:<br>- k的选择类似<br>- 思路类似：根据最近的样本来判断某个样本的属性</p>
<p>二者的不同点：</p>
<ul>
<li>应用场景不同：前者是分类或者回归问题，后者是聚类问题;</li>
<li>算法复杂度： 前者O（n^2）,后者O（kmn）;（k是聚类类别数，m是聚类次数）</li>
<li>稳定性：前者稳定，后者不稳定。</li>
</ul>
<h1>总结</h1>
<p>本文概括地描述了K近邻算法和K-means算法，具体比较了二者的算法步骤。在此基础上，通过将两种方法应用到实际问题中，更深入地比较二者的异同，以及各自的优劣。本文作者还分别实现了K近邻算法和K-means算法，并且应用到了具体问题上，最后得到了结果。<br>以上内容难免有所纰漏和错误，欢迎指正。</p>
<h1>源代码</h1>
<ul>
<li>KNN: <a href="https://github.com/shuaijiang/KNN" target="_blank"><a href="https://github.com/shuaijiang/KNN">https://github.com/shuaijiang/KNN</a></a></li>
<li>k-means: <a href="https://github.com/shuaijiang/k-means" target="_blank"><a href="https://github.com/shuaijiang/k-means">https://github.com/shuaijiang/k-means</a></a></li>
</ul>
<h1>参考文献</h1>
<ol>
<li>李航. 统计学习方法.清华大学出版社.2012</li>
</ol>

      
    </div>
    <footer>
      
        
        
  
  <div class="tags">
    <a href="/tags/机器学习/">机器学习</a>
  </div>

        
  <div class="addthis addthis_toolbox addthis_default_style">
    
      <a class="addthis_button_facebook_like" fb:like:layout="button_count"></a>
    
    
      <a class="addthis_button_tweet"></a>
    
    
      <a class="addthis_button_google_plusone" g:plusone:size="medium"></a>
    
    
      <a class="addthis_button_pinterest_pinit" pi:pinit:layout="horizontal"></a>
    
    <a class="addthis_counter addthis_pill_style"></a>
  </div>
  <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js"></script>

<!-- JiaThis Button BEGIN -->
<div class="jiathis_style_32x32">
	<a class="jiathis_button_qzone"></a>
	<a class="jiathis_button_tsina"></a>
	<a class="jiathis_button_tqq"></a>
	<a class="jiathis_button_weixin"></a>
	<a class="jiathis_button_renren"></a>
	<a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	<a class="jiathis_counter_style"></a>
</div>
<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1394007265544852" charset="utf-8"></script>
<!-- JiaThis Button END -->
      
      <div class="clearfix"></div>
    </footer>
  </div>
</article>


<!--likaci tab.js init begin-->
<script type="text/javascript" src="/js/tab.js"></script>
<script type="text/javascript">
    window.onload=function(){
         var tabtype={trigger:'mouseover',tabCurrentClass:'newclass',auto:false,timer:4000,delay:300 };
         tabInit(tabtype,['Disqus_bt','disqus_thread'],['duoshuo_bt','ds-thread'])
    }
</script>
<!--likaic tab.js init end-->
<!--likaci css style begin-->
<style type="text/css">
#Disqus_bt,#duoshuo_bt { padding: 5px 10px 5px 7px; line-height: 17px; display: block; float: left; margin: 0 7px 0 0; background-color: #f5f5f5; border: 1px solid #dedede; border-top: 1px solid #eee; border-left: 1px solid #eee; }
#Disqus_bt{color: #336699}
#duoshuo_bt{color: #d12f19}
#duoshuo_bt.newclass{background-color:#DFF4FF}
#Disqus_bt.newclass{background-color:#E6EFC2}
</style>
<!--likaci css style end-->

<section id="comment">
<!-- Duoshuo Comment BEGIN -->
	<div class="ds-thread"></div>
<script type="text/javascript">
var duoshuoQuery = {short_name:"shuaijiang"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = 'http://static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		|| document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
<!-- Duoshuo Comment END -->

</section>

<!-- UJian Button BEGIN -->
<script type="text/javascript" src="http://v1.ujian.cc/code/ujian.js?type=slide&fade=1"></script>
<a href="http://www.ujian.cc" style="border:0;"><img src="http://img.ujian.cc/pixel.png" alt="�Ѽ����Ƽ�" style="border:0;padding:0;margin:0;" /></a>
<!-- UJian Button END -->

</div></div>
    <aside id="sidebar" class="alignright">
  <div align=center>
	<script charset="Shift_JIS" src="http://chabudai.sakura.ne.jp/blogparts/honehoneclock/honehone_clock_tr.js"></script><!--shuaijaing-->
</div>

  <div class="search">
  <form action="//google.com/search" method="get" accept-charset="utf-8">
    <input type="search" name="q" results="0" placeholder="搜索">
    <input type="hidden" name="q" value="site:shuaijiang.github.io">
  </form>
</div>

  

  
<div class="widget tag">
  <h3 class="title">标签</h3>
  <ul class="entry">
  
    <li><a href="/tags/PaperReading/">PaperReading</a><small>4</small></li>
  
    <li><a href="/tags/Perl/">Perl</a><small>1</small></li>
  
    <li><a href="/tags/ubuntu/">ubuntu</a><small>1</small></li>
  
    <li><a href="/tags/信息浪潮/">信息浪潮</a><small>1</small></li>
  
    <li><a href="/tags/机器学习/">机器学习</a><small>3</small></li>
  
    <li><a href="/tags/语音合成/">语音合成</a><small>7</small></li>
  
    <li><a href="/tags/语音识别/">语音识别</a><small>1</small></li>
  
    <li><a href="/tags/随笔/">随笔</a><small>2</small></li>
  
  </ul>
</div>


  <html>
<body>
	<iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=550&fansRow=2&ptype=1&speed=0&skin=1&isTitle=1&noborder=1&isWeibo=1&isFans=1&uid=1967944471&verifier=2b0f09b7&dpc=1"></iframe>
</body>
</html>
</aside>
    <div class="clearfix"></div>
    
  </div>
  
  <footer id="footer" class="inner"><div class="alignleft">
  
  &copy; 2015 shuaijiang
  
</div>
<div class="clearfix"></div></footer>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>
<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>




<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

</body>
</html>